{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring @/caffe2/caffe2/contrib/nccl:nccl_ops as it is not a valid file.\n",
      "Ignoring @/caffe2/caffe2/contrib/gloo:gloo_ops as it is not a valid file.\n",
      "Ignoring @/caffe2/caffe2/contrib/gloo:gloo_ops_gpu as it is not a valid file.\n",
      "Data folder found at /Data\n"
     ]
    }
   ],
   "source": [
    "from caffe2.python import core, workspace, model_helper, net_drawer, memonger, brew, optimizer\n",
    "from caffe2.python import data_parallel_model as dpm\n",
    "from caffe2.python.models import alexnet\n",
    "from caffe2.proto import caffe2_pb2\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from IPython import display\n",
    "    \n",
    "workspace.GlobalInit(['caffe2', '--caffe2_log_level=2'])\n",
    "\n",
    "# This section checks if you have the training and testing databases\n",
    "current_folder = os.path.join(os.path.expanduser('~'), 'caffe2_notebooks')\n",
    "#data_folder = \"/data\"\n",
    "data_folder = \"/Data\"\n",
    "\n",
    "# Train/test data\n",
    "#train_data_db = os.path.join(data_folder, \"imagenet_cars_boats_train\")\n",
    "train_data_db = os.path.join(data_folder, \"train_db\")\n",
    "train_data_db_type = \"lmdb\"\n",
    "#train_data_count = 1280\n",
    "train_data_count = 1281167\n",
    "#test_data_db = os.path.join(data_folder, \"imagenet_cars_boats_val\")\n",
    "test_data_db = os.path.join(data_folder, \"val_db\")\n",
    "test_data_db_type = \"lmdb\"\n",
    "#test_data_count = 96\n",
    "test_data_count = 50000\n",
    "\n",
    "# Make the data folder if it doesn't exist\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "else:\n",
    "    print(\"Data folder found at {}\".format(data_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Configure how you want to train the model and with how many GPUs\n",
    "# This is set to use two GPUs in a single machine, but if you have more GPUs, extend the array [0, 1, 2, n]\n",
    "gpus = [0,1,2,3,4,5]\n",
    "\n",
    "# Batch size of 128 sums up to roughly 5GB of memory per device\n",
    "batch_per_device = 128\n",
    "num_gpus = len(gpus)\n",
    "print num_gpus\n",
    "total_batch_size = batch_per_device * num_gpus\n",
    "\n",
    "# This model discriminates between two labels: car or boat\n",
    "num_labels = 1000\n",
    "\n",
    "# Initial learning rate (scale with total batch size)\n",
    "base_learning_rate = 0.01\n",
    "\n",
    "# only intends to influence the learning rate after 10 epochs\n",
    "#stepsize = int(10 * train_data_count / total_batch_size)\n",
    "\n",
    "# Weight decay (L2 regularization)\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "workspace.ResetWorkspace()\n",
    "# 1. Use the model helper to create a CNN for us\n",
    "train_arg_scope = {\n",
    "    'order': 'NCHW',\n",
    "    'use_cudnn': True,\n",
    "    'cudnn_exhaustive_search': True,\n",
    "#    'ws_nbytes_limit': (args.cudnn_workspace_limit_mb * 1024 * 1024),\n",
    "}\n",
    "train_model = model_helper.ModelHelper(\n",
    "    # Arbitrary name for referencing the network in your workspace: you could call it tacos or boatzncarz\n",
    "    name=\"train\", arg_scope=train_arg_scope\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Create a database reader\n",
    "# This training data reader is shared between all GPUs.\n",
    "# When reading data, the trainer runs ImageInputOp for each GPU to retrieve their own unique batch of training data.\n",
    "# CreateDB is inherited by ModelHelper from model_helper.py\n",
    "# We are going to name it \"train_reader\" and pass in the db configurations we set earlier\n",
    "reader = train_model.CreateDB(\n",
    "    \"train_reader\",\n",
    "    db=train_data_db,\n",
    "    db_type=train_data_db_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_image_input_ops(model):\n",
    "    # utilize the ImageInput operator to prep the images\n",
    "    data, label = brew.image_input(\n",
    "        model,\n",
    "        reader,\n",
    "        [\"data\", \"label\"],\n",
    "        batch_size=batch_per_device,\n",
    "        use_gpu_transform=True if model._device_type == 1 else False,\n",
    "        use_caffe_datum=True,\n",
    "        # mean: to remove color values that are common\n",
    "        mean=128.,\n",
    "        # std is going to be modified randomly to influence the mean subtraction\n",
    "        std=128.,\n",
    "        # scale to rescale each image to a common size\n",
    "        scale=256,\n",
    "        # crop to the square each image to exact dimensions\n",
    "        crop=227,\n",
    "        # not running in test mode\n",
    "        is_test=False,\n",
    "        # mirroring of the images will occur randomly\n",
    "        mirror=1\n",
    "    )\n",
    "    # prevent back-propagation: optional performance improvement; may not be observable at small scale\n",
    "    data = model.net.StopGradient(data, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_alexnet_model_ops(model, loss_scale=1.0):\n",
    "    # Creates an alexnet network\n",
    "    pred = alexnet.create_alexnet(\n",
    "        model,\n",
    "        \"data\",\n",
    "        num_input_channels=3,\n",
    "        num_labels=num_labels,\n",
    "        no_bias=True,\n",
    "        no_loss=True,\n",
    "    )\n",
    "    softmax, loss = model.SoftmaxWithLoss([pred, 'label'],\n",
    "                                          ['softmax', 'loss'])\n",
    "    loss = model.Scale(loss, scale=loss_scale)\n",
    "    brew.accuracy(model, [softmax, \"label\"], \"accuracy\")\n",
    "    return [loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_optimizer(model):\n",
    "    #stepsz = int(30 * args.epoch_size / total_batch_size / num_shards)\n",
    "    optimizer.add_weight_decay(model, weight_decay)\n",
    "    opt = optimizer.build_multi_precision_sgd(\n",
    "        model,\n",
    "        base_learning_rate,\n",
    "        momentum=0.9,\n",
    "        nesterov=1,\n",
    "        policy=\"fixed\",\n",
    "        #stepsize=stepsz,\n",
    "        gamma=0.1\n",
    "    )\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_post_sync_ops(model):\n",
    "    \"\"\"Add ops applied after initial parameter sync.\"\"\"\n",
    "    for param_info in model.GetOptimizationParamInfo(model.GetParams()):\n",
    "        if param_info.blob_copy is not None:\n",
    "            model.param_init_net.HalfToFloat(\n",
    "                param_info.blob,\n",
    "                param_info.blob_copy[core.DataType.FLOAT]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"data_parallel_model\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assumes you're using the functions created in Part 4, 5, 6\n",
    "dpm.Parallelize(\n",
    "    train_model,\n",
    "    input_builder_fun=add_image_input_ops,\n",
    "    forward_pass_builder_fun=create_alexnet_model_ops,\n",
    "    optimizer_builder_fun=add_optimizer,\n",
    "    post_sync_builder_fun=add_post_sync_ops,\n",
    "    devices=gpus,\n",
    "    optimize_gradient_memory=True,\n",
    ")\n",
    "\n",
    "workspace.RunNetOnce(train_model.param_init_net)\n",
    "workspace.CreateNet(train_model.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iteration    1/1668 (epoch 1/1) (112.54 images/sec)\n",
      "Finished iteration   41/1668 (epoch 1/1) (2638.11 images/sec)\n",
      "Finished iteration   81/1668 (epoch 1/1) (2832.14 images/sec)\n",
      "Finished iteration  121/1668 (epoch 1/1) (2691.88 images/sec)\n",
      "Finished iteration  161/1668 (epoch 1/1) (2584.45 images/sec)\n",
      "Finished iteration  201/1668 (epoch 1/1) (2814.55 images/sec)\n",
      "Finished iteration  241/1668 (epoch 1/1) (2554.95 images/sec)\n",
      "Finished iteration  281/1668 (epoch 1/1) (2790.05 images/sec)\n",
      "Finished iteration  321/1668 (epoch 1/1) (2806.91 images/sec)\n",
      "Finished iteration  361/1668 (epoch 1/1) (3031.02 images/sec)\n",
      "Finished iteration  401/1668 (epoch 1/1) (2725.98 images/sec)\n",
      "Finished iteration  441/1668 (epoch 1/1) (2709.37 images/sec)\n",
      "Finished iteration  481/1668 (epoch 1/1) (2811.56 images/sec)\n",
      "Finished iteration  521/1668 (epoch 1/1) (2728.10 images/sec)\n",
      "Finished iteration  561/1668 (epoch 1/1) (2817.64 images/sec)\n",
      "Finished iteration  601/1668 (epoch 1/1) (2689.59 images/sec)\n",
      "Finished iteration  641/1668 (epoch 1/1) (2818.49 images/sec)\n",
      "Finished iteration  681/1668 (epoch 1/1) (2680.38 images/sec)\n",
      "Finished iteration  721/1668 (epoch 1/1) (2602.77 images/sec)\n"
     ]
    }
   ],
   "source": [
    "# Start looping through epochs where we run the batches of images to cover the entire dataset\n",
    "# Usually you would want to run a lot more epochs to increase your model's accuracy\n",
    "num_epochs = 1\n",
    "iter_interval = 40\n",
    "T1 = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    # Split up the images evenly: total images / batch size\n",
    "    num_iters = int(train_data_count / total_batch_size)\n",
    "    for iter in range(num_iters):\n",
    "        # Stopwatch start!\n",
    "        t1 = time.time()\n",
    "        # Run this iteration!\n",
    "        workspace.RunNet(train_model.net.Proto().name)\n",
    "        t2 = time.time()\n",
    "        dt = t2 - t1\n",
    "        \n",
    "        # Stopwatch stopped! How'd we do?\n",
    "        if iter%iter_interval == 0:\n",
    "            print((\n",
    "                \"Finished iteration {:>\" + str(len(str(num_iters))) + \"}/{}\" +\n",
    "                \" (epoch {:>\" + str(len(str(num_epochs))) + \"}/{})\" + \n",
    "                \" ({:.2f} images/sec)\").\n",
    "                format(iter+1, num_iters, epoch+1, num_epochs, total_batch_size/dt))\n",
    "T2 = time.time()\n",
    "DT = T2 - T1\n",
    "print ((\"Overall GPU performance ({:.2f} images/sec)\").\n",
    "      format(num_iters*total_batch_size/DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
